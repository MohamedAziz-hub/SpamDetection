# app_bilingual.py - VERSION CORRIG√âE
import streamlit as st
import joblib
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer, PorterStemmer
import os

# Configuration de la page
st.set_page_config(
    page_title="D√©tecteur de Spam Bilingue",
    page_icon="üåç",
    layout="centered"
)

# Titre bilingue
st.title("üåç D√©tecteur de Spam Intelligent")
st.markdown("""
**D√©tecte les spams en Fran√ßais et Anglais** üá´üá∑ üá¨üáß

Cette application utilise l'**Intelligence Artificielle** pour identifier les messages ind√©sirables.
""")


class BilingualSpamDetector:
    def __init__(self):
        # DEBUG: Afficher le chemin actuel
        current_dir = os.getcwd()
        st.sidebar.write(f"üìÅ Dossier actuel: {current_dir}")

        # Chemins complets vers les mod√®les
        model_path = os.path.join('models', 'bilingual_spam_model.pkl')
        vectorizer_path = os.path.join('models', 'bilingual_vectorizer.pkl')

        st.sidebar.write(f"üîç Recherche mod√®le: {model_path}")
        st.sidebar.write(f"üîç Recherche vectorizer: {vectorizer_path}")

        # V√©rifier si les fichiers existent
        model_exists = os.path.exists(model_path)
        vectorizer_exists = os.path.exists(vectorizer_path)

        st.sidebar.write(f"üìÑ Mod√®le existe: {model_exists}")
        st.sidebar.write(f"üìÑ Vectorizer existe: {vectorizer_exists}")

        # Charger le mod√®le et vectorizer
        try:
            if model_exists and vectorizer_exists:
                self.model = joblib.load(model_path)
                self.vectorizer = joblib.load(vectorizer_path)
                self.model_loaded = True
                st.sidebar.success("‚úÖ Mod√®les charg√©s avec succ√®s!")
            else:
                st.error("‚ùå Fichiers de mod√®le manquants")
                self.model_loaded = False

        except Exception as e:
            st.error(f"‚ùå Erreur de chargement: {e}")
            self.model_loaded = False

        # Initialiser les outils de pr√©traitement
        try:
            nltk.data.find('corpora/stopwords')
            self.stopwords_fr = set(stopwords.words('french'))
            self.stopwords_en = set(stopwords.words('english'))
        except LookupError:
            nltk.download('stopwords')
            self.stopwords_fr = set(stopwords.words('french'))
            self.stopwords_en = set(stopwords.words('english'))

        self.stemmer_fr = SnowballStemmer("french")
        self.stemmer_en = PorterStemmer()

    def detect_language(self, text):
        """D√©tecte la langue du texte"""
        text_lower = text.lower()

        french_indicators = ['le', 'la', 'les', 'de', 'des', 'du', 'et', 'est', '√†', 'vous', 'nous']
        english_indicators = ['the', 'and', 'is', 'in', 'to', 'of', 'for', 'you', 'we']

        french_count = sum(1 for word in french_indicators if word in text_lower)
        english_count = sum(1 for word in english_indicators if word in text_lower)

        return 'fr' if french_count > english_count else 'en'

    def clean_text(self, text, language='auto'):
        """Nettoie le texte pour l'analyse"""
        if not text or text.strip() == '':
            return ''

        if language == 'auto':
            language = self.detect_language(text)

        # Nettoyage de base
        text = text.lower()

        if language == 'fr':
            text = re.sub(r'[^a-zA-Z√†√¢√§√©√®√™√´√Æ√Ø√¥√∂√π√ª√º√ß\s]', '', text)
            stop_words = self.stopwords_fr
            stemmer = self.stemmer_fr
        else:
            text = re.sub(r'[^a-zA-Z\s]', '', text)
            stop_words = self.stopwords_en
            stemmer = self.stemmer_en

        # Tokenization et stemming
        words = text.split()
        cleaned_words = []

        for word in words:
            if word not in stop_words and len(word) > 2:
                stemmed_word = stemmer.stem(word)
                cleaned_words.append(stemmed_word)

        return ' '.join(cleaned_words)

    def predict(self, text):
        """Fait une pr√©diction sur le texte"""
        if not self.model_loaded:
            return None, None, None, None

        # Nettoyer le texte
        language = self.detect_language(text)
        cleaned_text = self.clean_text(text, language)

        # Vectoriser
        text_vectorized = self.vectorizer.transform([cleaned_text])

        # Pr√©dire
        prediction = self.model.predict(text_vectorized)[0]
        probability = self.model.predict_proba(text_vectorized)[0]

        return prediction, probability, language, cleaned_text


# Initialiser le d√©tecteur
detector = BilingualSpamDetector()

# Interface utilisateur
if detector.model_loaded:
    # Zone de texte
    user_input = st.text_area(
        "üìù Entrez le message √† analyser:",
        placeholder="Collez votre email ou message ici (Fran√ßais ou Anglais)...",
        height=150
    )

    # Options
    col1, col2 = st.columns(2)
    with col1:
        auto_detect = st.checkbox("D√©tection automatique de langue", value=True)
    with col2:
        if not auto_detect:
            language_choice = st.radio("Choisir la langue:", ["Fran√ßais", "Anglais"])
        else:
            language_choice = "Auto"

    # Bouton d'analyse
    if st.button("üîç Analyser le message", type="primary", use_container_width=True):
        if user_input.strip():
            with st.spinner("Analyse en cours..."):
                # Pr√©diction
                lang_param = 'auto' if auto_detect else language_choice.lower()[:2]
                prediction, probability, detected_lang, cleaned_text = detector.predict(user_input)

                if prediction is not None:
                    # Affichage des r√©sultats
                    st.markdown("---")
                    st.subheader("üìä R√©sultats de l'analyse")

                    # R√©sultat principal
                    if prediction == 1:  # SPAM
                        st.error(f"üö® **SPAM D√âTECT√â**")
                        confidence = probability[1]
                        st.metric("Niveau de confiance", f"{confidence:.2%}")
                    else:  # HAM
                        st.success(f"‚úÖ **MESSAGE NORMAL**")
                        confidence = probability[0]
                        st.metric("Niveau de confiance", f"{confidence:.2%}")

                    # D√©tails techniques
                    with st.expander("üîß D√©tails techniques"):
                        st.write(f"**Langue d√©tect√©e:** {detected_lang.upper()}")
                        st.write(f"**Probabilit√© SPAM:** {probability[1]:.4f}")
                        st.write(f"**Probabilit√© HAM:** {probability[0]:.4f}")
                        st.write(f"**Texte nettoy√©:** {cleaned_text}")
        else:
            st.warning("‚ö†Ô∏è Veuillez entrer un message √† analyser.")
else:
    st.error("""
    ‚ùå **Mod√®le non charg√©**

    Pour r√©soudre ce probl√®me:

    1. **V√©rifiez que les fichiers existent:**
    ```bash
    ls models/
    ```

    2. **Si les fichiers manquent, r√©-entra√Ænez le mod√®le:**
    ```bash
    python train_bilingual.py
    ```

    3. **Red√©marrez l'application:**
    ```bash
    streamlit run app_bilingual.py
    ```
    """)

# Section d'information
with st.sidebar:
    st.header("üéØ Exemples √† tester")

    st.subheader("üá´üá∑ Spams Fran√ßais")
    st.code("F√©licitations ! Vous avez gagn√© 1 000 000 ‚Ç¨ !")

    st.subheader("üá¨üáß English Spams")
    st.code("Congratulations! You won $1000000!")

    st.subheader("üìß Messages normaux")
    st.code("Bonjour, comment allez-vous ?")
    st.code("Hello, how are you doing?")